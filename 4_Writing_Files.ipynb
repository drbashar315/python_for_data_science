{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing new files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writer object\n",
    "A writer object lets you write data to a CSV file. \n",
    "To create a writer object, you use the csv.writer() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['value1', 'value2', 'value3', 'value4']\n",
      "['Value, 5', 'value6', 'value7', 'value8']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe csv module handles the extra commas put inside the values.\\nIt does not create 2 seperate values if it finds a comma INSIDE a value. \\nSee value 5 for example  .. this is a huge advantage!\\n\\nDon't forget to set the newline parameter as nothing! ... it means put nothing inside those quotation marks '',\\nBecause if you don't do that, the output CSV will contain a blanc row inbetween each of the rows containing data!\\nWell, that is true for the windows OS, I didn't have this problem in others.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "Output_CSV = open('output_example1.csv', 'w', newline='')\n",
    "Writer = csv.writer(Output_CSV)\n",
    "Writer.writerow(['value1', 'value2', 'value3', 'value4'])\n",
    "Writer.writerow(['Value, 5', 'value6', 'value7', 'value8'])\n",
    "Output_CSV.close()\n",
    "\n",
    "with open('output_example1.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        print(line)\n",
    "'''\n",
    "The csv module handles the extra commas that are (confusingly) put inside the values.\n",
    "The module does not create 2 seperate values if it finds a comma INSIDE a value. \n",
    "See value 5 for example  .. this is a huge advantage!\n",
    "\n",
    "Don't forget to set the newline parameter as nothing! ... it means put nothing inside those quotation marks '',\n",
    "Because if you don't do that, the output CSV will contain a blanc row inbetween each of the rows containing data!\n",
    "Well, that is true for the windows OS, I didn't have this problem in others.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DictReader and DictWriter CSV Objects\n",
    "\n",
    "From \"Automate the Boring Stuff with Python, 2nd Edition\" (https://www.google.com/books/edition/Automate_the_Boring_Stuff_with_Python_2n/TVz6DwAAQBAJ?hl=en&gbpv=0)\n",
    "\n",
    "\n",
    "For CSV files that contain header rows, it’s often more convenient to work with the DictReader and DictWriter objects,\n",
    "rather than the reader and writer objects.\n",
    "\n",
    "The reader and writer objects read and write to CSV file rows by using lists. \n",
    "The DictReader and DictWriter CSV objects perform the same functions but use dictionaries instead, \n",
    "and they use the first row of the CSV file as the keys of these dictionaries.\n",
    "\n",
    "\n",
    "### DictReader Objects\n",
    "Inside the loop, DictReader object sets row to a dictionary object with keys derived from the headers in the first row. (Well, technically, it sets row to an OrderedDict object, which you can use in the same way as a dictionary; the difference between them is beyond the scope of this book.) Using a DictReader object means you don’t need additional code to skip the first row’s header information, since the DictReader object does this for you.\n",
    "\n",
    "DictWriter objects use dictionaries to create CSV files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('Fruit', 'Cucumber'), ('Taste', 'Weird'), ('Diabetic_Code', '0_Can eat unlimited')]), OrderedDict([('Fruit', 'Grape'), ('Taste', 'Sweet'), ('Diabetic_Code', '2_Can not eat')]), OrderedDict([('Fruit', 'Strawberry'), ('Taste', 'Sour'), ('Diabetic_Code', '')])]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "Output_CSV2 = open('output_example2.csv', 'w', newline='')\n",
    "DictWriter = csv.DictWriter(Output_CSV2, ['Fruit', 'Taste', 'Diabetic_Code'])\n",
    "DictWriter.writeheader()\n",
    "DictWriter.writerow({'Fruit': 'Cucumber', 'Taste': 'Weird', 'Diabetic_Code': '0_Can eat unlimited'})\n",
    "\n",
    "DictWriter.writerow({'Fruit': 'Grape', 'Taste': 'Sweet', 'Diabetic_Code': '2_Can not eat'})\n",
    "DictWriter.writerow({'Taste': 'Sour', 'Fruit': 'Strawberry'})\n",
    "\n",
    "Output_CSV2.close()\n",
    "lines =[]\n",
    "with open('output_example2.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "f.close()\n",
    "print(lines[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new CSV taking subset of a larger file\n",
    "\n",
    "Here is a handy code chunk that will help you to create a new CSV file with only one out of every hundred rows of a large CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The codes below are to create a new csv  which is a subset (having only 1 row for every 100 rows) of the original file\n",
    "# Name of the new csv: 'subset_pvsubset.csv' \n",
    "# Name of the original csv: 'pvsubset.csv'\n",
    "# Both CSV files are given in this repository\n",
    "import csv\n",
    "f1 = open('subset_pvsubset.csv',\"w\", newline ='') # A new CSV is being created! Hence the \"w\" mode.\n",
    "f1.write(\"\") # This will clear the content of the file. Handy for repeated  testing the creation of an output file with same code!\n",
    "f1.close()\n",
    "line = 0 # Setting a counter so that we can use this to write specific lines in the output file\n",
    "f1 = open('subset_pvsubset.csv',\"a\")\n",
    "writer = csv.writer(f1, delimiter = ',', lineterminator = '\\n')\n",
    "\n",
    "with open('pvsubset.csv', 'r') as f2:\n",
    "    reader = csv.reader(f2)\n",
    "    for row in reader:\n",
    "        if line == 0: # A simele way to write the header in the output file!\n",
    "            writer.writerow(row)\n",
    "        elif line % 100 == 0: # This will ensure writing 1 for each 100 rows from the source file.\n",
    "            writer.writerow(row)\n",
    "        line+=1            \n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the newly written CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Summons Number', 'Plate ID', 'Registration State', 'Issue Date', 'Violation Code', 'Vehicle Body Type', 'Vehicle Make', 'Vehicle Expiration Date', 'House Number', 'Street Name', 'Vehicle Color', 'Vehicle Year'] \n",
      "\n",
      "['1363748579', 'RR76Y0', 'PA', '7/9/2015', '20', 'SUBN', 'VOLKS', '0', '543', 'ATLANTIC AVE', 'GY', '0'] \n",
      "\n",
      "['1320811292', 'GXD9050', 'NY', '6/21/2017', '40', 'SUBN', 'NISSA', '20170303', '1050', 'SOUNDVIEW AVE', 'GRAY', '2005'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking content of new csv\n",
    "n =0\n",
    "with open('subset_pvsubset.csv', 'r') as nf:\n",
    "    reader = csv.reader(nf)\n",
    "    for row in reader:\n",
    "        print(row, '\\n')\n",
    "        if n >1:\n",
    "            break\n",
    "        n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing file sizes (original VS new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original file size : 8641694\n",
      "New file size : 86412\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Original file size : \"+str(os.stat('pvsubset.csv').st_size))\n",
    "print(\"New file size : \"+str(os.stat('subset_pvsubset.csv').st_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
